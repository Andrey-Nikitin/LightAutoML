{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.1. Import necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard python libraries\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "logging.basicConfig(format='[%(asctime)s] (%(levelname)s): %(message)s', level=logging.INFO)\n",
    "\n",
    "# Installed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Imports from our package\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.dataset.roles import DatetimeRole\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.utils.profiler import Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.2. Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 8 # threads cnt for lgbm and linear models\n",
    "N_FOLDS = 5 # folds cnt for AutoML\n",
    "RANDOM_STATE = 42 # fixed random state for various reasons\n",
    "TEST_SIZE = 0.2 # Test size for metric check\n",
    "TIMEOUT = 300 # Time in seconds for automl run\n",
    "TARGET_NAME = 'TARGET' # Target column name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.3. Fix torch number of threads and numpy seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.4. Change profiling decorators settings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, profiling decorators are turned off for speed and memory reduction. If you want to see profiling report after using LAMA, you need to turn on the decorators using command below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Profiler()\n",
    "p.change_deco_settings({'enabled': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.5. Example data load "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we use local Hadoop cluster which is not pre-configured in this tutorial.\n",
    "\n",
    "You may need to create your own (see https://github.com/big-data-europe/docker-hadoop for quick example) or set url of existing cluster in `client_options`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to train and/or test datasets on HDFS\n",
    "# This paths should start with hdfs:// to be interpreted as HDFS-based sources\n",
    "train_data = \"hdfs:///automl/train.csv\"\n",
    "test_data = \"hdfs:///automl/test.csv\"\n",
    "\n",
    "read_csv_params = {\n",
    "    # Parameters for python HDFS client\n",
    "    # For reference see https://hdfscli.readthedocs.io/en/latest/api.html#module-hdfs.client\n",
    "    \"client_options\": {\n",
    "        'url': \"http://namenode:9870\"\n",
    "    },\n",
    "    # Optional parameters for HDFS data reader\n",
    "    # For reference see https://hdfscli.readthedocs.io/en/latest/api.html#hdfs.client.Client.read\n",
    "    \"hdfs_reader_options\": {\n",
    "        \n",
    "    },\n",
    "    # Optional parameters for Pandas reader options\n",
    "    # For csv reader reference see https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "    # and for parquet reader reference see https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html\n",
    "    \"pandas_reader_options\": {\n",
    "        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========= AutoML preset usage =========\n",
    "\n",
    "\n",
    "## Step 1. Create Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "task = Task('binary', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Setup columns roles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roles setup here set target column and base date, which is used to calculate date differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "roles = {'target': TARGET_NAME,\n",
    "         DatetimeRole(base_date=True, seasonality=(), base_feats=False): 'report_dt',\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Create AutoML from preset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create AutoML model here we use `TabularAutoML` preset, which looks like:\n",
    "\n",
    "![TabularAutoML preset pipeline](imgs/tutorial_2_pipeline.png)\n",
    "\n",
    "All params we set above can be send inside preset to change its configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "automl = TabularAutoML(task = task, \n",
    "                       timeout = TIMEOUT,\n",
    "                       general_params = {'nested_cv': False, 'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n",
    "                       reader_params = {'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
    "                       tuning_params = {'max_tuning_iter': 20, 'max_tuning_time': 30},\n",
    "                       lgb_params = {'default_params': {'num_threads': N_THREADS}},\n",
    "                       read_csv_params=read_csv_params)\n",
    "oof_pred = automl.fit_predict(train_data, roles = roles)\n",
    "logging.info('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Predict to test data and check scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_pred = automl.predict(test_data)\n",
    "logging.info('Prediction for test data:\\n{}\\nShape = {}'\n",
    "              .format(test_pred, test_pred.shape))\n",
    "\n",
    "logging.info('Check scores...')\n",
    "logging.info('OOF score: {}'.format(roc_auc_score(train_data[TARGET_NAME].values, oof_pred.data[:, 0])))\n",
    "logging.info('TEST score: {}'.format(roc_auc_score(test_data[TARGET_NAME].values, test_pred.data[:, 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Profiling AutoML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build report here, we **must** turn on decorators on step 0.4. Report is interactive and you can go as deep into functions call stack as you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "p.profile('my_report_profile.html')\n",
    "assert os.path.exists('my_report_profile.html'), 'Profile report failed to build'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Create AutoML with time utilization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are going to create specific AutoML preset for TIMEOUT utilization (try to spend it as much as possible):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "automl = TabularUtilizedAutoML(task = task, \n",
    "                       timeout = TIMEOUT,\n",
    "                       general_params = {'nested_cv': False, 'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n",
    "                       reader_params = {'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
    "                       tuning_params = {'max_tuning_iter': 20, 'max_tuning_time': 30},\n",
    "                       lgb_params = {'default_params': {'num_threads': N_THREADS}})\n",
    "oof_pred = automl.fit_predict(train_data, roles = roles)\n",
    "logging.info('oof_pred:\\n{}\\nShape = {}'.format(oof_pred, oof_pred.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Predict to test data and check scores for utilized automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_pred = automl.predict(test_data)\n",
    "logging.info('Prediction for test data:\\n{}\\nShape = {}'\n",
    "              .format(test_pred, test_pred.shape))\n",
    "\n",
    "logging.info('Check scores...')\n",
    "logging.info('OOF score: {}'.format(roc_auc_score(train_data[TARGET_NAME].values, oof_pred.data[:, 0])))\n",
    "logging.info('TEST score: {}'.format(roc_auc_score(test_data[TARGET_NAME].values, test_pred.data[:, 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8. Profiling utilized AutoML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build report here, we **must** turn on decorators on step 0.4. Report is interactive and you can go as deep into functions call stack as you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "p.profile('my_report_profile.html')\n",
    "assert os.path.exists('my_report_profile.html'), 'Profile report failed to build'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix. Profiling report screenshots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading HTML with profiling report, you can see fully folded report (please wait for green LOAD OK text for full load finish). If you click on triangle on the left, it unfolds and look like this:  \n",
    "\n",
    "<img src=\"imgs/tutorial_2_initial_report.png\" alt=\"Initial profiling report\" style=\"width: 500px;\"/>\n",
    "\n",
    "If we go even deeper we will receive situation like this:\n",
    "\n",
    "<img src=\"imgs/tutorial_2_unfolded_report.png\" alt=\"Profiling report after several unfoldings on different levels\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}