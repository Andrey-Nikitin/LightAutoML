{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard python libraries\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "logging.basicConfig(format='[%(asctime)s] (%(levelname)s): %(message)s', level=logging.INFO)\n",
    "\n",
    "# Installed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Imports from our package\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.dataset.roles import DatetimeRole\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.utils.profiler import Profiler\n",
    "\n",
    "from lightautoml.addons.uplift.base import AutoUplift\n",
    "from lightautoml.addons.uplift import meta_learners\n",
    "from lightautoml.addons.uplift.metrics import (_available_uplift_modes,\n",
    "                                               calculate_graphic_uplift_curve,\n",
    "                                               calculate_min_max_uplift_auc,\n",
    "                                               calculate_uplift_auc,\n",
    "                                               perfect_uplift_curve)\n",
    "from lightautoml.addons.uplift.utils import create_linear_automl\n",
    "from lightautoml.report.report_deco import ReportDecoUplift\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 8 # threads cnt for lgbm and linear models\n",
    "N_FOLDS = 5 # folds cnt for AutoML\n",
    "RANDOM_STATE = 42 # fixed random state for various reasons\n",
    "TEST_SIZE = 0.2 # Test size for metric check\n",
    "TIMEOUT = 300 # Time in seconds for automl run\n",
    "TARGET_NAME = 'TARGET' # Target column name\n",
    "TREATMENT_NAME = 'TREATMENT' # Treatment column name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix torch number of threads and numpy seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data = pd.read_csv('./example_data/test_data_files/sampled_app_train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Some user feature preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "data['BIRTH_DATE'] = (np.datetime64('2018-01-01') + data['DAYS_BIRTH'].astype(np.dtype('timedelta64[D]'))).astype(str)\n",
    "data['EMP_DATE'] = (np.datetime64('2018-01-01') + np.clip(data['DAYS_EMPLOYED'], None, 0).astype(np.dtype('timedelta64[D]'))\n",
    "                    ).astype(str)\n",
    "\n",
    "data['report_dt'] = np.datetime64('2018-01-01')\n",
    "\n",
    "data['constant'] = 1\n",
    "data['allnan'] = np.nan\n",
    "\n",
    "data.drop(['DAYS_BIRTH', 'DAYS_EMPLOYED'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create treatment column with synthetic values (only for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "data[TREATMENT_NAME] = np.nan\n",
    "data.loc[data[TARGET_NAME] == 0, TREATMENT_NAME] = \\\n",
    "    np.random.randint(2, size=data.loc[data[TARGET_NAME] == 0].shape[0])\n",
    "data.loc[data[TARGET_NAME] == 1, TREATMENT_NAME] = \\\n",
    "    np.random.choice([0, 1], data[data[TARGET_NAME] == 1].shape[0], p=[0.3, 0.7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data splitting for train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train, test = train_test_split(data, test_size=2000, random_state=42, shuffle=True)\n",
    "\n",
    "test_target, test_treatment = test[TARGET_NAME].values.ravel(), test[TREATMENT_NAME].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup columns roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "roles = {\n",
    "    'target': TARGET_NAME,\n",
    "    'treatment': TREATMENT_NAME,\n",
    "    DatetimeRole(base_date=True, seasonality=(), base_feats=False): 'report_dt'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uplift modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoUplift (automaticaly choose best uplift method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit autouplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Set uplift candidate for choosing best of them\n",
    "# !!!ATTENTION!!!\n",
    "#    This is a demonstration of the possibilities, \n",
    "#    You may use default set of candidates \n",
    "#\n",
    "# Format: ('String_Name', 'MetaLearnerClass', 'Parameter for MetaLearnerClass')\n",
    "\n",
    "task = Task('binary')\n",
    "\n",
    "uplift_candidates = [\n",
    "    (\n",
    "        'TLearner__Default', \n",
    "        meta_learners.TLearner, \n",
    "        {'base_task': task}\n",
    "    ),  \n",
    "    (\n",
    "        'XLearner__Custom',\n",
    "        meta_learners.XLearner,\n",
    "        {\n",
    "            'outcome_learners': [\n",
    "                TabularAutoML(task=task, timeout=10), # [sec] , Only speed up example, don't change it!\n",
    "                create_linear_automl(base_task=Task('binary'))\n",
    "            ],\n",
    "            'effect_learners': [TabularAutoML(task=Task('reg'), timeout=5)],\n",
    "            'propensity_learner': create_linear_automl(base_task=Task('binary')),\n",
    "        }    \n",
    "    )\n",
    "]\n",
    "\n",
    "autouplift = AutoUplift(Task('binary'),\n",
    "                        uplift_candidates=uplift_candidates, \n",
    "                        add_dd_candidates=True,\n",
    "                        metric='adj_qini', \n",
    "                        normed_metric=True, \n",
    "                        test_size=0.2)\n",
    "\n",
    "# !!!ATTENTION!!! \n",
    "# Only speed up example, don't change it!\n",
    "\n",
    "autouplift.__TABULAR_DEFAULT_TIME__ = 10\n",
    "autouplift.__THRESHOLD_DISBALANCE_TREATMENT__ = 0.0\n",
    "\n",
    "autouplift.fit(train, roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show rating of uplift methods (meta-learners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rating_table = autouplift.get_metalearners_ranting()\n",
    "rating_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict to test data and check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "uplift_pred, treatment_pred, control_pred = autouplift.predict(test)\n",
    "uplift_pred = uplift_pred.ravel()\n",
    "\n",
    "roc_auc_treatment = roc_auc_score(test_target[test_treatment == 1], treatment_pred[test_treatment == 1])\n",
    "roc_auc_control = roc_auc_score(test_target[test_treatment == 0], control_pred[test_treatment == 0])\n",
    "\n",
    "uplift_auc_algo = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=False)\n",
    "uplift_auc_algo_normed = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=True)\n",
    "auc_base, auc_perfect = calculate_min_max_uplift_auc(test_target, test_treatment)\n",
    "\n",
    "logging.info('--- Check scores ---')\n",
    "logging.info('OOF scores \"ROC_AUC\":')\n",
    "logging.info('\\tTreatment = %f', roc_auc_treatment)\n",
    "logging.info('\\tControl   = %f', roc_auc_control)\n",
    "logging.info('Uplift score of test group (default=\"adj_qini\"):')\n",
    "logging.info('\\tBaseline      = %f', auc_base)\n",
    "logging.info('\\tAlgo (Normed) = %f (%f)', uplift_auc_algo, uplift_auc_algo_normed)\n",
    "logging.info('\\tPerfect       = %f', auc_perfect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Get best metalearner with report functionaly (should refit on train data for generating report) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "best_metalearner_repo = autouplift.create_best_meta_learner(need_report=True)\n",
    "best_metalearner_repo.fit(train, roles)\n",
    "best_metalearner_repo.predict(test)\n",
    "\n",
    "# Path to report: PATH_TO_CURRENT_NOTEBOOK/lama_report/lama_interactive_report.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MetaLearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TLearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Default setting\n",
    "tlearner = meta_learners.TLearner(base_task=Task('binary'))\n",
    "tlearner.fit(train, roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict to test data and check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "uplift_pred, treatment_pred, control_pred = tlearner.predict(test)\n",
    "uplift_pred = uplift_pred.ravel()\n",
    "\n",
    "roc_auc_treatment = roc_auc_score(test_target[test_treatment == 1], treatment_pred[test_treatment == 1])\n",
    "roc_auc_control = roc_auc_score(test_target[test_treatment == 0], control_pred[test_treatment == 0])\n",
    "\n",
    "uplift_auc_algo = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=False)\n",
    "uplift_auc_algo_normed = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=True)\n",
    "auc_base, auc_perfect = calculate_min_max_uplift_auc(test_target, test_treatment)\n",
    "\n",
    "logging.info('--- Check scores ---')\n",
    "logging.info('OOF scores \"ROC_AUC\":')\n",
    "logging.info('\\tTreatment = %f', roc_auc_treatment)\n",
    "logging.info('\\tControl   = %f', roc_auc_control)\n",
    "logging.info('Uplift score of test group (default=\"adj_qini\"):')\n",
    "logging.info('\\tBaseline      = %f', auc_base)\n",
    "logging.info('\\tAlgo (Normed) = %f (%f)', uplift_auc_algo, uplift_auc_algo_normed)\n",
    "logging.info('\\tPerfect       = %f', auc_perfect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XLearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Custom base algorithm\n",
    "xlearner = meta_learners.XLearner(\n",
    "    propensity_learner=TabularAutoML(task=Task('binary'), timeout=10),\n",
    "    outcome_learners=[\n",
    "        TabularAutoML(task=Task('binary'), timeout=10),\n",
    "        TabularAutoML(task=Task('binary'), timeout=10)\n",
    "    ],\n",
    "    effect_learners=[\n",
    "        TabularAutoML(task=Task('reg'), timeout=10),\n",
    "        TabularAutoML(task=Task('reg'), timeout=10)\n",
    "    ]\n",
    ")\n",
    "xlearner.fit(train, roles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict to test data and check metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "uplift_pred, treatment_pred, control_pred = xlearner.predict(test)\n",
    "uplift_pred = uplift_pred.ravel()\n",
    "\n",
    "roc_auc_treatment = roc_auc_score(test_target[test_treatment == 1], treatment_pred[test_treatment == 1])\n",
    "roc_auc_control = roc_auc_score(test_target[test_treatment == 0], control_pred[test_treatment == 0])\n",
    "\n",
    "uplift_auc_algo = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=False)\n",
    "uplift_auc_algo_normed = calculate_uplift_auc(test_target, uplift_pred, test_treatment, normed=True)\n",
    "auc_base, auc_perfect = calculate_min_max_uplift_auc(test_target, test_treatment)\n",
    "\n",
    "logging.info('--- Check scores ---')\n",
    "logging.info('OOF scores \"ROC_AUC\":')\n",
    "logging.info('\\tTreatment = %f', roc_auc_treatment)\n",
    "logging.info('\\tControl   = %f', roc_auc_control)\n",
    "logging.info('Uplift score of test group (default=\"adj_qini\"):')\n",
    "logging.info('\\tBaseline      = %f', auc_base)\n",
    "logging.info('\\tAlgo (Normed) = %f (%f)', uplift_auc_algo, uplift_auc_algo_normed)\n",
    "logging.info('\\tPerfect       = %f', auc_perfect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uplift metrics and graphics (using xlearner predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "UPLIFT_METRIC = 'adj_qini'\n",
    "\n",
    "logging.info(\"All available uplift metrics: %s\", _available_uplift_modes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm uplift curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Algorithm curve\n",
    "xs_xlearner, ys_xlearner = calculate_graphic_uplift_curve(\n",
    "    test_target, uplift_pred, test_treatment, mode=UPLIFT_METRIC\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline, perfect curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline curve\n",
    "xs_base, ys_base = [0, 1], [0, ys_xlearner[-1]]\n",
    "\n",
    "# Perfect curver\n",
    "perfect_uplift = perfect_uplift_curve(test_target, test_treatment)\n",
    "xs_perfect, ys_perfect = calculate_graphic_uplift_curve(\n",
    "    test_target, perfect_uplift, test_treatment, mode=UPLIFT_METRIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(xs_base, ys_base, 'black')\n",
    "plt.plot(xs_xlearner, ys_xlearner, 'red')\n",
    "plt.plot(xs_perfect, ys_perfect, 'green')\n",
    "\n",
    "plt.fill_between(xs_xlearner, ys_xlearner, alpha=0.5, color='orange')\n",
    "\n",
    "plt.xlabel('Cumulative percentage of people in T/C groups')\n",
    "plt.ylabel('Uplift metric (%s)'.format(UPLIFT_METRIC))\n",
    "plt.grid()\n",
    "plt.legend(['Baseline', 'XLearner', 'Perfect']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "RDU = ReportDecoUplift()\n",
    "tlearner_deco = RDU(meta_learners.TLearner(base_task=Task('binary')))\n",
    "tlearner_deco.fit(train, roles)\n",
    "tlearner_deco.predict(test);\n",
    "\n",
    "# Path to report: PATH_TO_CURRENT_NOTEBOOK/lama_report/lama_interactive_report.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('lama_venv')",
   "language": "python",
   "name": "python38564bitlamavenv59c2c471446542c5a82f1a901d0eaec6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
